{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1875312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.HwTR import HwR\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21a0663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras import backend as F\n",
    "\n",
    "\n",
    "class HwTR:\n",
    "    def __init__(self, img_w, img_h, max_text_length, num_classes, letters):\n",
    "        self.IMG_W = img_w\n",
    "        self.IMG_H = img_h\n",
    "        self.MAX_TEXT_LENGTH = max_text_length\n",
    "        self.num_classes = num_classes\n",
    "        self.letters = letters\n",
    "\n",
    "        self.training_model, self.inference_model = self._build_models()\n",
    "\n",
    "    # =====================================================================\n",
    "    # --------------------------- BUILD MODELS -----------------------------\n",
    "    # =====================================================================\n",
    "    def _build_models(self):\n",
    "\n",
    "        input_data = layers.Input(\n",
    "            name='input', shape=(self.IMG_W, self.IMG_H, 1), dtype='float32'\n",
    "        )\n",
    "\n",
    "        # ----------------------- CNN BODY -----------------------\n",
    "        x = layers.Conv2D(64, (3,3), padding='same', kernel_initializer='he_normal')(input_data)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "        x = layers.Conv2D(128, (3,3), padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "        x = layers.Conv2D(256, (3,3), padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.Conv2D(256, (3,3), padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.MaxPooling2D((1,2))(x)\n",
    "\n",
    "        x = layers.Conv2D(512, (3,3), padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.Conv2D(512, (3,3), padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.MaxPooling2D((1,2))(x)\n",
    "\n",
    "        x = layers.MaxPooling2D((2,1))(x)\n",
    "\n",
    "        x = layers.Conv2D(512, (2,2), padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "        # ----------------------- CNN → RNN -----------------------\n",
    "        x = layers.Reshape((16, 2048))(x)\n",
    "        x = layers.Dense(64, activation='relu', kernel_initializer='he_normal')(x)\n",
    "\n",
    "        x = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(x)\n",
    "        x = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        y_pred = layers.Dense(self.num_classes, kernel_initializer='he_normal')(x)\n",
    "        y_pred = layers.Activation('softmax', name='softmax')(y_pred)\n",
    "\n",
    "        # ----------------------- CTC Inputs -----------------------\n",
    "        labels = layers.Input(name=\"the_labels\", shape=[self.MAX_TEXT_LENGTH], dtype=\"int32\")\n",
    "        input_length = layers.Input(name=\"input_length\", shape=[1], dtype=\"int32\")\n",
    "        label_length = layers.Input(name=\"label_length\", shape=[1], dtype=\"int32\")\n",
    "\n",
    "        # CTC\n",
    "        loss_out = layers.Lambda(\n",
    "            lambda args: F.ctc_batch_cost(args[1], args[0], args[2], args[3]),\n",
    "            name=\"ctc\"\n",
    "        )([y_pred, labels, input_length, label_length])\n",
    "\n",
    "        training_model = Model(\n",
    "            inputs=[input_data, labels, input_length, label_length],\n",
    "            outputs=loss_out\n",
    "        )\n",
    "\n",
    "        inference_model = Model(input_data, y_pred)\n",
    "\n",
    "        return training_model, inference_model\n",
    "\n",
    "    # =====================================================================\n",
    "    # ----------------------------- PREPROCESS -----------------------------\n",
    "    # =====================================================================\n",
    "    def add_padding(self, img, old_w, old_h, new_w, new_h):\n",
    "        h1, h2 = int((new_h - old_h) / 2), int((new_h - old_h) / 2) + old_h\n",
    "        w1, w2 = int((new_w - old_w) / 2), int((new_w - old_w) / 2) + old_w\n",
    "        img_pad = np.ones([new_h, new_w, 3]) * 255\n",
    "        img_pad[h1:h2, w1:w2, :] = img\n",
    "        return img_pad\n",
    "\n",
    "    def fix_size(self, img, target_w, target_h):\n",
    "        h, w = img.shape[:2]\n",
    "        if w < target_w and h < target_h:\n",
    "            img = self.add_padding(img, w, h, target_w, target_h)\n",
    "        elif w >= target_w and h < target_h:\n",
    "            new_w = target_w\n",
    "            new_h = int(h * new_w / w)\n",
    "            new_img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "            img = self.add_padding(new_img, new_w, new_h, target_w, target_h)\n",
    "        elif w < target_w and h >= target_h:\n",
    "            new_h = target_h\n",
    "            new_w = int(w * new_h / h)\n",
    "            new_img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "            img = self.add_padding(new_img, new_w, new_h, target_w, target_h)\n",
    "        else:\n",
    "            ratio = max(w / target_w, h / target_h)\n",
    "            new_w = max(min(target_w, int(w / ratio)), 1)\n",
    "            new_h = max(min(target_h, int(h / ratio)), 1)\n",
    "            new_img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "            img = self.add_padding(new_img, new_w, new_h, target_w, target_h)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def preprocess(self, path):\n",
    "        img = cv2.imread(path)\n",
    "        img = self.fix_size(img, self.IMG_W, self.IMG_H)\n",
    "    \n",
    "        img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        img = img.astype(np.float32) / 255.0\n",
    "    \n",
    "        img = img.T                                 # ★ critical\n",
    "        img = np.expand_dims(img, axis=-1)          # (128, 64, 1)\n",
    "        img = np.expand_dims(img, axis=0)           # (1, 128, 64, 1)\n",
    "    \n",
    "        return img\n",
    "\n",
    "\n",
    "    # =====================================================================\n",
    "    # ----------------------------- DECODE -----------------------------\n",
    "    # =====================================================================\n",
    "    def decode(self, preds):\n",
    "        decoded = F.get_value(\n",
    "            F.ctc_decode(\n",
    "                preds,\n",
    "                input_length=np.ones(preds.shape[0]) * preds.shape[1],\n",
    "                greedy=True\n",
    "            )[0][0]\n",
    "        )\n",
    "\n",
    "        result = []\n",
    "        for seq in decoded:\n",
    "            seq = seq[seq != -1]\n",
    "            text = \"\".join(self.letters[i] for i in seq)\n",
    "            result.append(text)\n",
    "        return result[0] if len(result) > 0 else \"\"\n",
    "\n",
    "    # =====================================================================\n",
    "    # ----------------------------- PUBLIC API -----------------------------\n",
    "    # =====================================================================\n",
    "    def load(self, checkpoint):\n",
    "        self.inference_model.load_weights(checkpoint)\n",
    "        print(f\"✔ Weights loaded: {checkpoint}\")\n",
    "\n",
    "    def predict(self, img_tensor):\n",
    "        preds = self.inference_model.predict(img_tensor)\n",
    "        return self.decode(preds)\n",
    "\n",
    "    def preprocess_and_recognize(self, path):\n",
    "        img = self.preprocess(path)\n",
    "        return self.predict(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a997a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = os.path.join(\"model\",\"HwTR_V7.h5\")\n",
    "IMG_H = 64\n",
    "IMG_W = 128\n",
    "LETTERS = (\n",
    "    [' '] +\n",
    "    [str(d) for d in range(10)] +\n",
    "    [chr(c) for c in range(ord('A'), ord('Z')+1)] +\n",
    "    [chr(c) for c in range(ord('a'), ord('z')+1)]\n",
    ")\n",
    "\n",
    "hwr = HwTR(\n",
    "    img_w=128,\n",
    "    img_h=64,\n",
    "    max_text_length=16,\n",
    "    num_classes=len(LETTERS)+1,\n",
    "    letters=LETTERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cf02095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Weights loaded: model\\HwTR_V7.h5\n"
     ]
    }
   ],
   "source": [
    "hwr.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7148bcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "certain\n"
     ]
    }
   ],
   "source": [
    "test_image = \"demo.png\"\n",
    "result = hwr.preprocess_and_recognize(test_image)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handwriting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
